{
  
    
        "post0": {
            "title": "Title",
            "content": "Hello, my name is Artem. I&#39;m going to review your project! . You can find my comments in green, blue or red boxes like this: . Success: if everything is done succesfully Improve: &quot;Improve&quot; comments mean that there are tiny corrections that could help you to make your project better. Needs fixing: if the block requires some corrections. Work can&#39;t be accepted with the red comments. General feedback . Thank you for sending your project. You&#39;ve done a really good job on it! It was interesting to check. | The code style is very good. I was really surprised! | Glad to see that notebook is well-structured. | There are few things that need to be corrected in your project. | There are also some comments for improvement. They don’t mean that you’ve done anything wrong, but they’re things we wanted to point out that can help you further develop your skills. | You&#39;re on the right track! We are waiting for the new version of the project. | . General feedback (review 2) . Thanks for sending in your project with corrections. It&#39;s clear you&#39;ve put a lot of effort into it. | All new comments contain &#39;review 2&#39; keyword. | Some issues were corrected, another ones need a little more effort. | There are some new &quot;improve&quot; comments. Pay attention to them too. | Submit the new version as soon as it will be ready. | . General feedback (review 3) . I&#39;m happy to see you&#39;ve made a few corrections to your work! | Great that you&#39;ve mastered &#39;.groupby()&#39; and &#39;.pivot_table()&#39; methods. | Your project has been accepted and now you can move on to the next sprint. | Good luck on the next sprint! And remember, if you have any questions along the way, don&#39;t hesitate to reach out to your tutor! | . Analyzing borrowers&#8217; risk of defaulting . Your project is to prepare a report for a bank’s loan division. You’ll need to find out if a customer’s marital status and number of children has an impact on whether they will default on a loan. The bank already has some data on customers’ credit worthiness. . Your report will be considered when building a credit scoring of a potential customer. A credit scoring is used to evaluate the ability of a potential borrower to repay their loan. . Step 1. Open the data file and have a look at the general information. . import pandas as pd df = pd.read_csv(&#39;/datasets/credit_scoring_eng.csv&#39;) pd.set_option(&#39;display.max_row&#39;,100) df.info() # the days_employed are negative # there exists NaN values . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 21525 entries, 0 to 21524 Data columns (total 12 columns): children 21525 non-null int64 days_employed 19351 non-null float64 dob_years 21525 non-null int64 education 21525 non-null object education_id 21525 non-null int64 family_status 21525 non-null object family_status_id 21525 non-null int64 gender 21525 non-null object income_type 21525 non-null object debt 21525 non-null int64 total_income 19351 non-null float64 purpose 21525 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 2.0+ MB . Needs fixing: Please, don&#39;t forget about &#39;.info()&#39; method next time. Success (review 2): Well done! Conclusion . On first glace I noticed: . -days employed are negative . -there exists NaN values in the days_employed and total_income columns. It would be safe to say that the two columns are correlated because one cannot calculate total_income without days employed. The reason for the missing values could be human error. Maybe the employees are new hires so data does not exist as of yet. . -education needs to be lowercase -purpose might need to be grouped together? . Step 2. Data preprocessing . Processing missing values . df.isnull().sum() df.dropna(inplace=True) . Conclusion . I chose to drop the missing values because I do not have the data to fill them in. Filling in n/a with the mean value would be wrong. I could have also replaced the n/a values with 0. 2174 lines were dropped in days_employed and total_income. . Improve: This solution is acceptable but please print how many lines were dropped. Maybe you&#39;ve deleted all dataset? Data type replacement . df[&#39;days_employed&#39;] = df[&#39;days_employed&#39;].astype(int) df[&#39;days_employed&#39;] = df[&#39;days_employed&#39;].abs() df[&#39;total_income&#39;] = df[&#39;total_income&#39;].astype(int) df[&#39;education&#39;] = df[&#39;education&#39;].str.lower() df[&#39;purpose&#39;] = df[&#39;purpose&#39;].str.lower() df[&#39;family_status&#39;] = df[&#39;family_status&#39;].str.lower() df[&#39;income_type&#39;] = df[&#39;income_type&#39;].str.lower() df . children days_employed dob_years education education_id family_status family_status_id gender income_type debt total_income purpose . 0 | 1 | 8437 | 42 | bachelor&#39;s degree | 0 | married | 0 | F | employee | 0 | 40620 | purchase of the house | . 1 | 1 | 4024 | 36 | secondary education | 1 | married | 0 | F | employee | 0 | 17932 | car purchase | . 2 | 0 | 5623 | 33 | secondary education | 1 | married | 0 | M | employee | 0 | 23341 | purchase of the house | . 3 | 3 | 4124 | 32 | secondary education | 1 | married | 0 | M | employee | 0 | 42820 | supplementary education | . 4 | 0 | 340266 | 53 | secondary education | 1 | civil partnership | 1 | F | retiree | 0 | 25378 | to have a wedding | . ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 21520 | 1 | 4529 | 43 | secondary education | 1 | civil partnership | 1 | F | business | 0 | 35966 | housing transactions | . 21521 | 0 | 343937 | 67 | secondary education | 1 | married | 0 | F | retiree | 0 | 24959 | purchase of a car | . 21522 | 1 | 2113 | 38 | secondary education | 1 | civil partnership | 1 | M | employee | 1 | 14347 | property | . 21523 | 3 | 3112 | 38 | secondary education | 1 | married | 0 | M | employee | 1 | 39054 | buying my own car | . 21524 | 2 | 1984 | 40 | secondary education | 1 | married | 0 | F | employee | 0 | 13127 | to buy a car | . 19351 rows × 12 columns . Conclusion . -days employed is now int instead of float, the absolute value was taken to get positive numbers -total income was changed to int instead of float because the cents don&#39;t really matter -education was changed to lower to make categorization easier . Success: Well done! Processing duplicates . df2 = df.duplicated().sum() df.drop_duplicates().reset_index(drop=True) print(df.dtypes) . children int64 days_employed int64 dob_years int64 education object education_id int64 family_status object family_status_id int64 gender object income_type object debt int64 total_income int64 purpose object dtype: object . Conclusion . Duplicates if they existed are now dropped from the DataFrame using the drop_duplicates method. The drop_duplicates method was used with the argument &quot;inplace=True&quot; because we want the changes to be made on the original DataFrame. df2 = df.duplicated().sum() shows that there are 0 lines in the DataFrame that are duplicated. No lines were deleted. . Improve: Please, print how many lines were deleted. Categorizing Data . def income_level(row): income = int(row[&#39;total_income&#39;]) if income &lt; 20000: return &#39;Poverty&#39; elif 20000 &lt;= income &lt;= 44000: return &#39;Low Income&#39; elif 45000 &lt;= income &lt;= 139000: return &#39;Middle Class&#39; elif 140000 &lt;= income &lt;= 149000: return &#39;Upper Middle Class&#39; elif 150000 &lt;= income &lt;= 199999: return &#39;High Income&#39; else: if income &gt;= 200000: return &#39;Highest Tax Bracket&#39; row_values = [&#39;1500000&#39;] row = pd.Series(data=row_values, index=[&#39;total_income&#39;]) income_level(row) df[&#39;income_level&#39;] = df.apply(income_level, axis=1) def have_kids(new_row): kids = int(new_row[&#39;children&#39;]) if kids &gt; 0: return &#39;1&#39; else: return &#39;0&#39; new_row_values = [&#39;0&#39;] new_row = pd.Series(data=new_row_values, index=[&#39;children&#39;]) have_kids(new_row) df[&#39;have_kids&#39;] = df.apply(have_kids, axis=1) # Creating Pivot Tables df[&#39;kids_ratio&#39;] = df[&#39;children&#39;]/df[&#39;children&#39;].sum() #df.pivot_table(index=[&#39;have_kids&#39;, &#39;kids_ratio&#39;], values=&#39;debt&#39;) df[&#39;kids_ratio&#39;].count() #df.pivot_table(index=&#39;family_status&#39;, values=&#39;debt&#39;) #df.pivot_table(index=&#39;income_level&#39;, values=&#39;debt&#39;) #df[&#39;income_level&#39;].value_counts() . 19351 . Conclusion . a correlation exists between the amount of children one has and the ability to repay a loan. There also exists a correlation between family status and the ability to repay a loan. . Needs fixing: You should categorize data by income level. The best solution is to create a new column. Improve (review 2): Categorization was done in the right way but it would be better if you&#39;ve created a new column (not replace values in income_level column). Hi reviewer, . Thank you for taking the time out to look at my code. I thought I created a new column. There are two columns. The original &#39;total_income&#39; and the column I created &#39;income_level&#39; based off of that column. . Success (review 3): Sorry, it was my fault. You&#39;re right a new column was created. Step 3. Answer these questions . Needs fixing (review 2): This tep should done in this way: question; calculations using pivot table/groupby. Ratios should ba calculated. This was done correctly: df.pivot_table(index=&#39;have_kids&#39;, values=&#39;debt&#39;) ; some conclusions based on pivot table. Is there a relation between having kids and repaying a loan on time? | . rate = df[&#39;debt&#39;].sum() / df.shape[0] #rate for all loans print(&quot;The rate for all loans is:&quot;, rate,&quot;%&quot;) print(df[&#39;children&#39;].corr(df[&#39;debt&#39;])) #noticed a negative value for children df[&#39;children&#39;] = df[&#39;children&#39;].replace([-1], 0) #replaces -1 w/ 0 df.groupby([&#39;children&#39;])[&#39;debt&#39;].agg([&#39;mean&#39;])[&#39;mean&#39;]*100 # 20 children seems a little outrageous .. could be an error . The rate for all loans is: 0.0811844349129244 % 0.02135295137788271 . children 0 7.472166 1 9.394428 2 9.562399 3 7.482993 4 8.823529 5 0.000000 20 11.940299 Name: mean, dtype: float64 . There does not seem to be a relation between having children and defaulting on loans. There does exist an outlier in the data set. . Improve (review 2): It would be better if conclusion was written in markdown cell, Conclusion . Is there a relation between marital status and repaying a loan on time? | . df.groupby([&#39;family_status&#39;])[&#39;debt&#39;].agg([&#39;mean&#39;])[&#39;mean&#39;]*100 . family_status civil partnership 9.076305 divorced 7.017544 married 7.592210 unmarried 10.059406 widow / widower 6.473988 Name: mean, dtype: float64 . results show that unmarried customers and customers in a civil partnership default more on loans. . Conclusion . Is there a relation between income level and repaying a loan on time? | . print(df[&#39;total_income&#39;].describe()) print(&quot;==============================&quot;) print(df.groupby([&#39;income_level&#39;])[&#39;debt&#39;].agg([&#39;mean&#39;])[&#39;mean&#39;]*100) . count 19351.000000 mean 26787.071262 std 16475.452412 min 3306.000000 25% 16488.000000 50% 23202.000000 75% 32549.500000 max 362496.000000 Name: total_income, dtype: float64 ============================== income_level High Income 5.882353 Highest Tax Bracket 9.090909 Low Income 8.239663 Middle Class 7.111597 Poverty 8.250780 Upper Middle Class 0.000000 Name: mean, dtype: float64 . The high income bracket has defaulted less on loans than the highest income tax bracket. Low Income and Poverty are about the same. Having the highest tax bracket be the highest defaulter of loans seems a bit weird. . Conclusion . How do different loan purposes affect on-time repayment of the loan? | . &quot;If the loan is for school or business, banks might not see a payment on the loan for a while. Versus if the loan is for a house, car, wedding, which are one time things, banks will see a payment after the event has happened&quot; . Conclusion . Needs fixing: These findings should be supported with calculations. For example, in first question you could create column have_kids = (1 if children &gt; 0 else 0). After that compare percentage users repaid the loan on time in 2 groups(have kids/ no kids). You could use &#39;groupby/pivot_table&#39; for it. Step 4. General conclusion . Data categorization is used in data to organize data into categories so it is easy to retrieve/sort data. . Using pivot tables and groupby, I was able to determine that there was no relation between having kids and defaulting on a loan. I was also able to determine that there was an outlier in the data which could have been human error. Using groupby I analyzed the relation between marital status and repaying a loan on time and income level and repaying a loan on time. . Different loan purposes affect on-time repayment because as stated in the conclusion above, one-time events such as weddings or car/house purchases will start to see payment after the event; school/business not so much as the customer might need to take out another loan. . Project Readiness Checklist . Put &#39;x&#39; in the completed points. Then press Shift + Enter. . [x] file open; | [x] file examined; | [x] missing values defined; | [x] missing values are filled; | [x] an explanation of which missing value types were detected; | [x] explanation for the possible causes of missing values; | [x] an explanation of how the blanks are filled; | [x] replaced the real data type with an integer; | [x] an explanation of which method is used to change the data type and why; | [x] duplicates deleted; | [x] an explanation of which method is used to find and remove duplicates; | [x] description of the possible reasons for the appearance of duplicates in the data; | [x] data is categorized; | [x] an explanation of the principle of data categorization; | [x] an answer to the question &quot;Is there a relation between having kids and repaying a loan on time?&quot;; | [x] an answer to the question &quot; Is there a relation between marital status and repaying a loan on time?&quot;; | [x] an answer to the question &quot; Is there a relation between income level and repaying a loan on time?&quot;; | [x] an answer to the question &quot; How do different loan purposes affect on-time repayment of the loan?&quot; | [x] conclusions are present on each stage; | [x] a general conclusion is made. | .",
            "url": "https://tylerana.github.io/Data-Science-Journey/2020/09/11/Data-Preprocessing.html",
            "relUrl": "/2020/09/11/Data-Preprocessing.html",
            "date": " • Sep 11, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "fastcore: An Underrated Python Library",
            "content": ". Background . I recently embarked on a journey to sharpen my python skills: I wanted to learn advanced patterns, idioms, and techniques. I started with reading books on advanced Python, however, the information didn&#39;t seem to stick without having somewhere to apply it. I also wanted the ability to ask questions from an expert while I was learning -- which is an arrangement that is hard to find! That&#39;s when it occurred to me: What if I could find an open source project that has fairly advanced python code and write documentation and tests? I made a bet that if I did this it would force me to learn everything very deeply, and the maintainers would be appreciative of my work and be willing to answer my questions. . And that&#39;s exactly what I did over the past month! I&#39;m pleased to report that it has been the most efficient learning experience I&#39;ve ever experienced. I&#39;ve discovered that writing documentation forced me to deeply understand not just what the code does but also why the code works the way it does, and to explore edge cases while writing tests. Most importantly, I was able to ask questions when I was stuck, and maintainers were willing to devote extra time knowing that their mentorship was in service of making their code more accessible! It turns out the library I choose, fastcore is some of the most fascinating Python I have ever encountered as its purpose and goals are fairly unique. . For the uninitiated, fastcore is a library on top of which many fast.ai projects are built on. Most importantly, fastcore extends the python programming language and strives to eliminate boilerplate and add useful functionality for common tasks. In this blog post, I&#39;m going to highlight some of my favorite tools that fastcore provides, rather than sharing what I learned about python. My goal is to pique your interest in this library, and hopefully motivate you to check out the documentation after you are done to learn more! . Why fastcore is interesting . Get exposed to ideas from other languages without leaving python: I’ve always heard that it is beneficial to learn other languages in order to become a better programmer. From a pragmatic point of view, I’ve found it difficult to learn other languages because I could never use them at work. Fastcore extends python to include patterns found in languages as diverse as Julia, Ruby and Haskell. Now that I understand these tools I am motivated to learn other languages. | You get a new set of pragmatic tools: fastcore includes utilities that will allow you to write more concise expressive code, and perhaps solve new problems. | Learn more about the Python programming language: Because fastcore extends the python programming language, many advanced concepts are exposed during the process. For the motivated, this is a great way to see how many of the internals of python work. | A whirlwind tour through fastcore . Here are some things you can do with fastcore that immediately caught my attention. . . Making **kwargs transparent . Whenever I see a function that has the argument **kwargs, I cringe a little. This is because it means the API is obfuscated and I have to read the source code to figure out what valid parameters might be. Consider the below example: . def baz(a, b=2, c =3, d=4): return a + b + c def foo(c, a, **kwargs): return c + baz(a, **kwargs) inspect.signature(foo) . &lt;Signature (c, a, **kwargs)&gt; . Without reading the source code, it might be hard for me to know that foo also accepts and additional parameters b and d. We can fix this with delegates: . def baz(a, b=2, c =3, d=4): return a + b + c @delegates(baz) # this decorator will pass down keyword arguments from baz def foo(c, a, **kwargs): return c + baz(a, **kwargs) inspect.signature(foo) . &lt;Signature (c, a, b=2, d=4)&gt; . You can customize the behavior of this decorator. For example, you can have your cake and eat it too by passing down your arguments and also keeping **kwargs: . @delegates(baz, keep=True) def foo(c, a, **kwargs): return c + baz(a, **kwargs) inspect.signature(foo) . &lt;Signature (c, a, b=2, d=4, **kwargs)&gt; . You can also exclude arguments. For example, we exclude argument d from delegation: . def basefoo(a, b=2, c =3, d=4): pass @delegates(basefoo, but= [&#39;d&#39;]) # exclude `d` def foo(c, a, **kwargs): pass inspect.signature(foo) . &lt;Signature (c, a, b=2)&gt; . You can also delegate between classes: . class BaseFoo: def __init__(self, e, c=2): pass @delegates()# since no argument was passsed here we delegate to the superclass class Foo(BaseFoo): def __init__(self, a, b=1, **kwargs): super().__init__(**kwargs) inspect.signature(Foo) . &lt;Signature (a, b=1, c=2)&gt; . For more information, read the docs on delegates. . . Avoid boilerplate when setting instance attributes . Have you ever wondered if it was possible to avoid the boilerplate involved with setting attributes in __init__? . class Test: def __init__(self, a, b ,c): self.a, self.b, self.c = a, b, c . Ouch! That was painful. Look at all the repeated variable names. Do I really have to repeat myself like this when defining a class? Not Anymore! Checkout store_attr: . class Test: def __init__(self, a, b, c): store_attr() t = Test(5,4,3) assert t.b == 4 . You can also exclude certain attributes: . class Test: def __init__(self, a, b, c): store_attr(but=[&#39;c&#39;]) t = Test(5,4,3) assert t.b == 4 assert not hasattr(t, &#39;c&#39;) . There are many more ways of customizing and using store_attr than I highlighted here. Check out the docs for more detail. . . Avoiding subclassing boilerplate . One thing I hate about python is the __super__().__init__() boilerplate associated with subclassing. For example: . class ParentClass: def __init__(self): self.some_attr = &#39;hello&#39; class ChildClass(ParentClass): def __init__(self): super().__init__() cc = ChildClass() assert cc.some_attr == &#39;hello&#39; # only accessible b/c you used super . We can avoid this boilerplate by using the metaclass PrePostInitMeta. We define a new class called NewParent that is a wrapper around the ParentClass: . class NewParent(ParentClass, metaclass=PrePostInitMeta): def __pre_init__(self, *args, **kwargs): super().__init__() class ChildClass(NewParent): def __init__(self):pass sc = ChildClass() assert sc.some_attr == &#39;hello&#39; . . Type Dispatch . Type dispatch, or Multiple dispatch, allows you to change the way a function behaves based upon the input types it receives. This is a prominent feature in some programming languages like Julia. For example, this is a conceptual example of how multiple dispatch works in Julia, returning different values depending on the input types of x and y: . collide_with(x::Asteroid, y::Asteroid) = ... # deal with asteroid hitting asteroid collide_with(x::Asteroid, y::Spaceship) = ... # deal with asteroid hitting spaceship collide_with(x::Spaceship, y::Asteroid) = ... # deal with spaceship hitting asteroid collide_with(x::Spaceship, y::Spaceship) = ... # deal with spaceship hitting spaceship . Type dispatch can be especially useful in data science, where you might allow different input types (i.e. Numpy arrays and Pandas dataframes) to a function that processes data. Type dispatch allows you to have a common API for functions that do similar tasks. . Unfortunately, Python does not support this out-of-the box. Fortunately, there is the @typedispatch decorator to the rescue. This decorator relies upon type hints in order to route inputs the correct version of the function: . @typedispatch def f(x:str, y:str): return f&#39;{x}{y}&#39; @typedispatch def f(x:np.ndarray): return x.sum() @typedispatch def f(x:int, y:int): return x+y . Below is a demonstration of type dispatch at work for the function f: . f(&#39;Hello &#39;, &#39;World!&#39;) . &#39;Hello World!&#39; . f(2,3) . 5 . f(np.array([5,5,5,5])) . 20 . There are limitations of this feature, as well as other ways of using this functionality that you can read about here. In the process of learning about typed dispatch, I also found a python library called multipledispatch made by Mathhew Rocklin (the creator of Dask). . After using this feature, I am now motivated to learn languages like Julia to discover what other paradigms I might be missing. . . A better version of functools.partial . functools.partial is a great utility that creates functions from other functions that lets you set default values. Lets take this function for example that filters a list to only contain values &gt;= val: . test_input = [1,2,3,4,5,6] def f(arr, val): &quot;Filter a list to remove any values that are less than val.&quot; return [x for x in arr if x &gt;= val] f(test_input, 3) . [3, 4, 5, 6] . You can create a new function out of this function using partial that sets the default value to 5: . filter5 = partial(f, val=5) filter5(test_input) . [5, 6] . One problem with partial is that it removes the original docstring and replaces it with a generic docstring: . filter5.__doc__ . &#39;partial(func, *args, **keywords) - new function with partial application n of the given arguments and keywords. n&#39; . fastcore.utils.partialler fixes this, and makes sure the docstring is retained such that the new API is transparent: . filter5 = partialler(f, val=5) filter5.__doc__ . &#39;Filter a list to remove any values that are less than val.&#39; . . Composition of functions . A technique that is pervasive in functional programming languages is function composition, whereby you chain a bunch of functions together to achieve some kind of result. This is especially useful when applying various data transformations. Consider a toy example where I have three functions: (1) Removes elements of a list less than 5 (from the prior section) (2) adds 2 to each number (3) sums all the numbers: . def add(arr, val): return [x + val for x in arr] def arrsum(arr): return sum(arr) # See the previous section on partialler add2 = partialler(add, val=2) transform = compose(filter5, add2, arrsum) transform([1,2,3,4,5,6]) . 15 . But why is this useful? You might me thinking, I can accomplish the same thing with: . arrsum(add2(filter5([1,2,3,4,5,6]))) . You are not wrong! However, composition gives you a convenient interface in case you want to do something like the following: . def fit(x, transforms:list): &quot;fit a model after performing transformations&quot; x = compose(*transforms)(x) y = [np.mean(x)] * len(x) # its a dumb model. Don&#39;t judge me return y # filters out elements &lt; 5, adds 2, then predicts the mean fit(x=[1,2,3,4,5,6], transforms=[filter5, add2]) . [7.5, 7.5] . For more information about compose, read the docs. . . A more useful __repr__ . In python, __repr__ helps you get information about an object for logging and debugging. Below is what you get by default when you define a new class. (Note: we are using store_attr, which was discussed earlier). . class Test: def __init__(self, a, b=2, c=3): store_attr() # `store_attr` was discussed previously Test(1) . &lt;__main__.Test at 0x7fe0ab662790&gt; . We can use basic_repr to quickly give us a more sensible default: . class Test: def __init__(self, a, b=2, c=3): store_attr() __repr__ = basic_repr(&#39;a,b,c&#39;) Test(2) . Test(a=2, b=2, c=3) . . Monkey Patching With A Decorator . It can be convenient to monkey patch with a decorator, which is especially helpful when you want to patch an external library you are importing. We can use the decorator @patch from fastcore.foundation along with type hints like so: . class MyClass(int): pass @patch def func(self:MyClass, a): return self+a mc = MyClass(3) . Now, MyClass has an additional method named func: . mc.func(10) . 13 . Still not convinced? I&#39;ll show you another example of this kind of patching in the next section. . . A better pathlib.Path . When you see these extensions to pathlib.path you won&#39;t ever use vanilla pathlib again! A number of additional methods have been added to pathlib, such as: . Path.readlines: same as with open(&#39;somefile&#39;, &#39;r&#39;) as f: f.readlines() | Path.read: same as with open(&#39;somefile&#39;, &#39;r&#39;) as f: f.read() | Path.save: saves file as pickle | Path.load: loads pickle file | Path.ls: shows the contents of the path as a list. | etc. | . Read more about this here. Here is a demonstration of ls: . from pathlib import Path p = Path(&#39;../_notebooks&#39;) p.ls() # you don&#39;t get this with vanilla Pathlib.Path!! . (#21) [Path(&#39;../_notebooks/gpt2_simple_mask.jpg&#39;),Path(&#39;../_notebooks/bert_mac_small.jpg&#39;),Path(&#39;../_notebooks/causal_with_prefix.jpg&#39;),Path(&#39;../_notebooks/.DS_Store&#39;),Path(&#39;../_notebooks/2020-03-07-How_to_Create_an_Automatic_Code_Comment_Generator_using_Deep_Learning.ipynb&#39;),Path(&#39;../_notebooks/2020-09-01-fastcore.ipynb&#39;),Path(&#39;../_notebooks/2020-03-07-Syntax-Highlighting.ipynb&#39;),Path(&#39;../_notebooks/2020-03-06-bart.ipynb&#39;),Path(&#39;../_notebooks/README.md&#39;),Path(&#39;../_notebooks/2020-05-01-TrainDonkeyCar.ipynb&#39;)...] . Wait! What&#39;s going on here? We just imported pathlib.Path - why are we getting this new functionality? Thats because we imported the fastcore.foundation module, which patches this module via the @patch decorator discussed earlier. Just to drive the point home on why the @patch decorator is useful, I&#39;ll go ahead and add another method to Path right now: . @patch def fun(self:Path): return &quot;This is fun!&quot; p.fun() . &#39;This is fun!&#39; . That is magical, right? I know! That&#39;s why I&#39;m writing about it! . . An Even More Concise Way To Create Lambdas . Self, with an uppercase S, is an even more concise way to create lambdas that are calling methods on an object. For example, let&#39;s create a lambda for taking the sum of a Numpy array: . arr=np.array([5,4,3,2,1]) f = lambda a: a.sum() assert f(arr) == 15 . You can use Self in the same way: . f = Self.sum() assert f(arr) == 15 . Let&#39;s create a lambda that does a groupby and max of a Pandas dataframe: . import pandas as pd df=pd.DataFrame({&#39;Some Column&#39;: [&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;b&#39;, ], &#39;Another Column&#39;: [5, 7, 50, 70]}) f = Self.groupby(&#39;Some Column&#39;).mean() f(df) . Another Column . Some Column . a 6 | . b 60 | . Read more about Self in the docs). . . Notebook Functions . These are simple but handy, and allow you to know whether or not code is executing in a Jupyter Notebook, Colab, or an Ipython Shell: . in_notebook(), in_colab(), in_ipython() . (True, False, True) . This is useful if you are displaying certain types of visualizations, progress bars or animations in your code that you may want to modify or toggle depending on the environment. . . A Drop-In Replacement For List . You might be pretty happy with Python&#39;s list. This is one of those situations that you don&#39;t know you needed a better list until someone showed one to you. Enter L, a list like object with many extra goodies. . The best way I can describe L is to pretend that list and numpy had a pretty baby: . define a list (check out the nice __repr__ that shows the length of the list!) . L(1,2,3) . (#3) [1,2,3] . Shuffle a list: . p = L.range(20).shuffle() p . (#20) [2,0,18,6,15,17,14,8,12,1...] . Index into a list: . p[2,4,6] . (#3) [18,15,14] . L has sensible defaults, for example appending an element to a list: . 1 + L(2,3,4) . (#4) [1,2,3,4] . There is much more L has to offer. Read the docs to learn more. . But Wait ... There&#39;s More! . There are more things I would like to show you about fastcore, but there is no way they would reasonably fit into a blog post. Here is a list of some of my favorite things that I didn&#39;t demo in this blog post: . Utilities . The Utilites section contain many shortcuts to perform common tasks or provide an additional interface to what standard python provides. . mk_class: quickly add a bunch of attributes to a class | wrap_class: add new methods to a class with a simple decorator | groupby: similar to Scala&#39;s groupby | merge: merge dicts | fasttuple: a tuple on steroids | Infinite Lists: useful for padding and testing | chunked: for batching and organizing stuff | . Multiprocessing . The Multiprocessing section extends python&#39;s multiprocessing library by offering features like: . progress bars | ability to pause to mitigate race conditions with external services | processing things in batches on each worker, ex: if you have a vectorized operation to perform in chunks | . Functional Programming . The functional programming section is my favorite part of this library. . maps: a map that also composes functions | mapped: A more robust map | using_attr: compose a function that operates on an attribute | . Transforms . Transforms is a collection of utilities for creating data transformations and associated pipelines. These transformation utilities build upon many of the building blocks discussed in this blog post. . Further Reading . It should be noted that you should read the main page of the docs first, followed by the section on tests to fully understand the documentation. . The fastcore documentation site. | The fastcore GitHub repo. | Blog post on delegation. | . Shameless plug: fastpages . This blog post was written entirely in a Jupyter Notebook, which GitHub automatically converted into to a blog post! Sound interesting? Check out fastpages. .",
            "url": "https://tylerana.github.io/Data-Science-Journey/fastcore/",
            "relUrl": "/fastcore/",
            "date": " • Sep 1, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://tylerana.github.io/Data-Science-Journey/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://tylerana.github.io/Data-Science-Journey/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://tylerana.github.io/Data-Science-Journey/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://tylerana.github.io/Data-Science-Journey/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}